{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c745e421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c83fb9-2211-430e-a67d-5fb5330a708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import quantities as pq\n",
    "import xml.etree.ElementTree as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regexp(expr, item):\n",
    "    reg = re.compile(expr)\n",
    "    return reg.search(item) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cea8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReadSession:\n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 path,\n",
    "                 animal_id,\n",
    "                 day,\n",
    "                 beh,\n",
    "                 session,\n",
    "                 unit_spiketime,\n",
    "                 unit_space,\n",
    "                 unit_lfp=pq.V,\n",
    "                 load_lfp=False):\n",
    "\n",
    "        meta_path = path + dataset + '/docs/' + dataset.replace('-', '') +\\\n",
    "                    '-metadata-tables/' + dataset.replace('-', '') +\\\n",
    "                    '-tables.db'\n",
    "\n",
    "        # Open database\n",
    "        con_sessions = sqlite3.connect(meta_path)\n",
    "        con_sessions.create_function(\"REGEXP\", 2, regexp)\n",
    "\n",
    "        topdir = animal_id + '.' + str(day)\n",
    "        subdir = animal_id + '.' + str(session)\n",
    "        \n",
    "        df_session = pd.read_sql_query(\n",
    "            'SELECT ' +\n",
    "            'topdir, ' +\n",
    "            'session, ' +\n",
    "            'behavior, ' +\n",
    "            'familiarity, ' +\n",
    "            'duration ' +\n",
    "            'from session where behavior=\\'' +\n",
    "            beh +\n",
    "            '\\' AND session=\\'' +\n",
    "            subdir +\n",
    "            '\\' AND topdir=\\'' +\n",
    "            topdir +\n",
    "            '\\'', con_sessions)\n",
    "\n",
    "        df_cells = pd.read_sql_query(\n",
    "            'SELECT ' +\n",
    "            'id, ' +\n",
    "            'topdir, ' +\n",
    "            'animal, ' +\n",
    "            'ele, ' +\n",
    "            'clu, ' +\n",
    "            'region, ' +\n",
    "            'nexciting, ' +\n",
    "            'ninhibiting, ' +\n",
    "            'exciting, ' +\n",
    "            'inhibiting, ' +\n",
    "            'excited, ' +\n",
    "            'inhibited, ' +\n",
    "            'fireRate, ' +\n",
    "            'totalFireRate, ' +\n",
    "            'cellType ' +\n",
    "            'From cell where topdir REGEXP \\'' +\n",
    "            topdir + '\\'',\n",
    "            con_sessions)\n",
    "        \n",
    "        df_epos = pd.read_sql_query(\n",
    "            'SELECT ' +\n",
    "            'topdir, ' +\n",
    "            'animal, ' +\n",
    "            'e1, ' +\n",
    "            'e2, ' +\n",
    "            'e3, ' +\n",
    "            'e4, ' +\n",
    "            'e5, ' +\n",
    "            'e6, ' +\n",
    "            'e7, ' +\n",
    "            'e8, ' +\n",
    "            'e9, ' +\n",
    "            'e10, ' +\n",
    "            'e11, ' +\n",
    "            'e12, ' +\n",
    "            'e13, ' +\n",
    "            'e14, ' +\n",
    "            'e15, ' +\n",
    "            'e16 ' +\n",
    "            'From epos where topdir REGEXP \\'' +\n",
    "            topdir + '\\'',\n",
    "            con_sessions)\n",
    "        \n",
    "        electrode_ids = np.unique(df_cells['ele'])\n",
    "        path_to_session = path + dataset + '/' + \\\n",
    "            topdir + '/' +\\\n",
    "            subdir + '.tar'\n",
    "\n",
    "        # extract variables from data\n",
    "        clusters = {}\n",
    "        times = {}\n",
    "        print('Get position and spikes')\n",
    "        with tf.open(path_to_session) as tf_session:\n",
    "            # get sampling rate of spike timestamps\n",
    "\n",
    "            xml_f = tf_session.extractfile(\n",
    "                subdir + '/' +\n",
    "                subdir + '.xml')\n",
    "            e = et.parse(xml_f).getroot()\n",
    "            sampling_rate_spike_time = float(\n",
    "                e.findall(\"./acquisitionSystem/samplingRate\")[0].text)\n",
    "\n",
    "            # get animal position\n",
    "            positions_file = tf_session.extractfile(\n",
    "                subdir + '/' +\n",
    "                subdir + '.whl')\n",
    "            positions_file_lines =[np.array(line.split(), dtype=np.float64) for line in positions_file.readlines()]\n",
    "    \n",
    "            positions = np.stack(positions_file_lines)\n",
    "            \n",
    "            \n",
    "            for ele_i in electrode_ids:\n",
    "                clusters_f = tf_session.extractfile(\n",
    "                    subdir + '/' +\n",
    "                    subdir + '.clu.' + str(ele_i))\n",
    "                # read cluster file\n",
    "                clusters_i = np.array([int(clu_id) for clu_id in clusters_f ])\n",
    "                # first line contains number of clusters in file, skip it\n",
    "                \n",
    "                \n",
    "                clusters_i = clusters_i[1:]\n",
    "                \n",
    "                times_f = tf_session.extractfile(\n",
    "                    subdir + '/' +\n",
    "                    subdir + '.res.' + str(ele_i))\n",
    "                # get times of spikes\n",
    "                times_i= np.array([float(time_j) for time_j in times_f])*unit_spiketime\n",
    "                # divide by sampling rate\n",
    "                times_i /= sampling_rate_spike_time\n",
    "                \n",
    "                # from documentation:\n",
    "                # cluster 0 corresponds to mechanical noise (the wave shapes\n",
    "                # do not look like neuron's spike). Cluster 1 corresponds to\n",
    "                # small, unsortable spikes. These two clusters (0 and 1) should\n",
    "                # not be used for analysis of neural data since they do not\n",
    "                # correspond to successfully sorted spikes.\n",
    "\n",
    "                # remove clusters == 0 and == 1\n",
    "                pos_cluster_not_0_or_1 = np.where(clusters_i >= 2)[0]\n",
    "                clusters_i = clusters_i[pos_cluster_not_0_or_1]\n",
    "                times_i = times_i[pos_cluster_not_0_or_1]\n",
    "                clusters[ele_i] = clusters_i\n",
    "                times[ele_i] = times_i\n",
    "\n",
    "                    \n",
    "        positions = positions * unit_space\n",
    "        \n",
    "        def data_spikes(electrode_ids,clusters,times):\n",
    "            combined_arrays = []\n",
    "            electrodeids = []\n",
    "            for i in electrode_ids:\n",
    "                combined_spike_time_i=np.column_stack((clusters[i],times[i]))\n",
    "                combined_arrays.append(combined_spike_time_i)\n",
    "                electrodeids_i = np.full((combined_spike_time_i.shape[0], 1), i)\n",
    "                electrodeids.append(electrodeids_i)\n",
    "\n",
    "\n",
    "            combined_array_all = np.vstack(\n",
    "                [np.hstack((electrodeids[i], combined_arrays[i])) for i in range(4)]\n",
    "            )\n",
    "\n",
    "            df = pd.DataFrame(data=combined_array_all, columns=['Electrode ID', 'Cluster', 'Time'])\n",
    "            return df\n",
    "\n",
    "        self.df_session = df_session\n",
    "        self.df_cells = df_cells\n",
    "        self.dataset = dataset\n",
    "        self.path = path\n",
    "        self.animal_id = animal_id\n",
    "        self.day = day\n",
    "        self.beh = beh\n",
    "        self.session = session\n",
    "        self.unit_spiketime = unit_spiketime\n",
    "        self.unit_space = unit_space\n",
    "        self.data_spikes= data_spikes(electrode_ids, clusters, times)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f290dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"hc-3\"\n",
    "path = \".../\"\n",
    "animal_id = \"\"\n",
    "day = \n",
    "beh = \"\"\n",
    "session = \n",
    "unit_spiketime = pq.ms\n",
    "unit_space = pq.mm\n",
    "load_lfp = False  # no need to set True!\n",
    "\n",
    "\n",
    "data=ReadSession(dataset,path,animal_id,day,beh,session,unit_spiketime,unit_space,load_lfp)\n",
    "\n",
    "data.data_spikes #give you a df of electrode ids, time spikes and clusters \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd4612",
   "metadata": {},
   "source": [
    "count the number of spikes in each neuron in each time bin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bin_width = 10  \n",
    "start_time = 0  \n",
    "end_time = 420\n",
    "time_bins = np.arange(start_time, end_time + bin_width, bin_width)\n",
    "\n",
    "def count_spikes_per_cluster(df, time_bins):\n",
    "    cluster_counts = []\n",
    "    for bin_start, bin_end in zip(time_bins[:-1], time_bins[1:]):\n",
    "        bin_counts = df[(df['Time'] >= bin_start) & (df['Time'] < bin_end)].groupby(['Cluster', 'Electrode ID']).count()['Time']\n",
    "        cluster_counts.append(bin_counts)\n",
    "    return pd.concat(cluster_counts, axis=1, keys=time_bins[:-1])\n",
    "\n",
    "spikes_counts_per_cluster = count_spikes_per_cluster(data.data_spikes, time_bins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685f8fc2",
   "metadata": {},
   "source": [
    "get correlation  between the counts of each neuron in time bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d6d422",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correlation_matrix = spikes_counts_per_cluster.corr()\n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
